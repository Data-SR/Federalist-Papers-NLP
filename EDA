##EDA 

#Libraries
import numpy as np
import pandas as pd
import nltk
nltk.download('punkt')
import re

df = pd.read_csv("C:\\Users\\sabri\\Desktop\\Federalist\\Data\\essay01.txt",sep='delimiter', header=None)

df.columns = ['Text']
df.index.names = ['Line']

from nltk.tokenize import sent_tokenize
sentences = []
for sentence in df['Text']:
    sentences.append(sent_tokenize(sentence))

sentences = [y for x in sentences for y in x] 

